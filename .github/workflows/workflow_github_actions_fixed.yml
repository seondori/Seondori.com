name: RAM Price Crawler (Cookie-Based)

on:
  schedule:
    - cron: '0 1 * * *'   # í•œêµ­ì‹œê°„ 10:00
    - cron: '0 4 * * *'   # í•œêµ­ì‹œê°„ 13:00
    - cron: '0 9 * * *'   # í•œêµ­ì‹œê°„ 18:00
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # â­ í•µì‹¬: ìµœì‹  Chrome ì„¤ì¹˜ (ë²„ì „ ë¬¸ì œ í•´ê²°)
      - name: Install latest Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      # â­ webdriver-managerë§Œ ì‚¬ìš© (manual chromedriver ì„¤ì • ì œê±°)
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install selenium webdriver-manager requests

      # Chrome ë²„ì „ í™•ì¸ (ë””ë²„ê¹…ìš©)
      - name: Check Chrome version
        run: |
          google-chrome --version
          which google-chrome

      - name: Run crawler
        env:
          NAVER_COOKIES: ${{ secrets.NAVER_COOKIES }}
          GITHUB_ACTIONS: true
        run: |
          cd backend
          python crawler_cookie_based.py

      - name: Check crawler results
        if: always()
        run: |
          if ls backend/ram_*.json 1> /dev/null 2>&1; then
            echo "âœ… í¬ë¡¤ëŸ¬ ê²°ê³¼ íŒŒì¼ í™•ì¸ë¨"
            ls -lah backend/ram_*.json
          else
            echo "âš ï¸ ê²°ê³¼ íŒŒì¼ ì—†ìŒ"
          fi

      - name: Commit and push changes
        if: success()
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          git add -A
          if git diff --staged --quiet; then
            echo "â„¹ï¸ ë³€ê²½ì‚¬í•­ ì—†ìŒ"
          else
            git commit -m "ğŸ¤– ìë™ ì—…ë°ì´íŠ¸: RAM ì‹œì„¸ $(date +'%Y-%m-%d %H:%M')"
            git push
          fi

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: crawler-logs-${{ github.run_id }}
          path: backend/
          retention-days: 7
